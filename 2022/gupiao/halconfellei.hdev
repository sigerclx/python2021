<?xml version="1.0" encoding="UTF-8"?>
<hdevelop file_version="1.2" halcon_version="20.11.1.0">
<procedure name="main">
<interface/>
<body>
<c>* </c>
<c>* Deep Learning classification workflow:</c>
<c>* </c>
<c>* This example demonstrates the overall workflow for</c>
<c>* classification based on deep learning.</c>
<c>* </c>
<c>* Please note:</c>
<c>* - This is a bare-bones example.</c>
<c>* - For this, default parameters are used as much as possible.</c>
<c>* - For more detailed steps, please refer to the respective examples from the series:</c>
<c>*   e.g. classify_pill_defects_deep_learning_1_preprocess.hdev etc.</c>
<c>* </c>
<l>dev_close_window ()</l>
<l>dev_update_off ()</l>
<l>set_system ('cudnn_deterministic', 'true')</l>
<l>PathExample:='D:/Python/python2021/2022/gupiao/601919/'</l>
<l>set_system ('seed_rand', 42)</l>
<c>* </c>
<c>* ***   0) SET INPUT/OUTPUT PATHS   ***</c>
<c>* </c>
<l>*get_system ('example_dir', PathExample)</l>
<c></c>
<c>* Give all folders that contain images.</c>
<l>ImageBaseFolder := PathExample </l>
<l>RawImageFolder := ImageBaseFolder + ['Z0','Z25','Z5','Z75','F25','F5','F75']</l>
<l>OutputDir := 'classify_fruits_data'</l>
<c>* Set to true, if the results should be deleted after running this program.</c>
<l>RemoveResults := false</l>
<c>* </c>
<c>* ***   1.) PREPARE   ***</c>
<c>* </c>
<c>* Read in a DLDataset.</c>
<c>* Alternatively, you can read in a DLDataset dictionary</c>
<c>* as created by e.g., the MVTec Deep Learning Tool using read_dict ().</c>
<l>read_dl_dataset_classification (RawImageFolder, 'last_folder', DLDataset)</l>
<c>* </c>
<c>* Read the pretrained classification model.</c>
<l>read_dl_model ('pretrained_dl_classifier_compact.hdl', DLModelHandle)</l>
<c>* Set the class names for the model.</c>
<l>get_dict_tuple (DLDataset, 'class_names', ClassNames)</l>
<l>set_dl_model_param (DLModelHandle, 'class_names', ClassNames)</l>
<c>* </c>
<c>* Preprocess the data in DLDataset.</c>
<l>split_dl_dataset (DLDataset, 70, 15, [])</l>
<c>* We explicitely want to use the model parameters to preprocess the dataset.</c>
<l>create_dl_preprocess_param_from_model (DLModelHandle, 'none', 'full_domain', [], [], [], DLPreprocessParam)</l>
<c>* </c>
<l>create_dict (PreprocessSettings)</l>
<l>set_dict_tuple (PreprocessSettings, 'overwrite_files', true)</l>
<l>preprocess_dl_dataset (DLDataset, OutputDir, DLPreprocessParam, PreprocessSettings, DLDatasetFileName)</l>
<c>* </c>
<c>* Inspect 10 randomly selected preprocessed DLSamples visually.</c>
<l>create_dict (WindowDict)</l>
<l>get_dict_tuple (DLDataset, 'samples', DatasetSamples)</l>
<l>for Index := 0 to 9 by 1</l>
<l>    SampleIndex := round(rand(1) * (|DatasetSamples| - 1))</l>
<l>    read_dl_samples (DLDataset, SampleIndex, DLSample)</l>
<l>    dev_display_dl_data (DLSample, [], DLDataset, 'classification_ground_truth', [], WindowDict)</l>
<l>    dev_disp_text ('Press Run (F5) to continue', 'window', 'bottom', 'right', 'black', [], [])</l>
<c>    //stop ()</c>
<l>endfor</l>
<l>dev_close_window_dict (WindowDict)</l>
<c>* </c>
<c>* ***   2.) TRAIN   ***</c>
<c>* </c>
<c>* Set training related model parameters.</c>
<c>* Training can be performed on a GPU or CPU.</c>
<c>* See the respective system requirements in the Installation Guide.</c>
<c>* If possible a GPU is used in this example.</c>
<c>* In case you explicitely wish to run this example on the CPU,</c>
<c>* choose the CPU device instead.</c>
<l>query_available_dl_devices (['runtime','runtime'], ['gpu','cpu'], DLDeviceHandles)</l>
<l>if (|DLDeviceHandles| == 0)</l>
<l>    throw ('No supported device found to continue this example.')</l>
<l>endif</l>
<c>* Due to the filter used in query_available_dl_devices, the first device is a GPU, if available.</c>
<l>DLDevice := DLDeviceHandles[0]</l>
<l>get_dl_device_param (DLDevice, 'type', DLDeviceType)</l>
<l>if (DLDeviceType == 'cpu')</l>
<c>    * The number of used threads may have an impact</c>
<c>    * on the training duration.</c>
<l>    NumThreadsTraining := 4</l>
<l>    set_system ('thread_num', NumThreadsTraining)</l>
<l>endif</l>
<c>* </c>
<c>* For details see the documentation of set_dl_model_param () and get_dl_model_param ().</c>
<l>set_dl_model_param (DLModelHandle, 'batch_size', 8)</l>
<l>set_dl_model_param (DLModelHandle, 'learning_rate', 0.001)</l>
<l>set_dl_model_param (DLModelHandle, 'device', DLDevice)</l>
<c>* </c>
<c>* Here, we run a short training of 20 epochs.</c>
<c>* For better model performance increase the number of epochs,</c>
<c>* from 20 to e.g., 40.</c>
<l>create_dl_train_param (DLModelHandle, 20, 1, 'true', 42, [], [], TrainParam)</l>
<c>* The training and thus the call of train_dl_model_batch ()</c>
<c>* is done using the following procedure.</c>
<l>train_dl_model (DLDataset, DLModelHandle, TrainParam, 0, TrainResults, TrainInfos, EvaluationInfos)</l>
<c>* </c>
<c>* Read the best model, which is written to file by train_dl_model.</c>
<l>read_dl_model ('model_best.hdl', DLModelHandle)</l>
<l>dev_disp_text ('Press F5 to continue', 'window', 'bottom', 'left', 'black', [], [])</l>
<l>stop ()</l>
<c>* </c>
<l>dev_close_window ()</l>
<l>dev_close_window ()</l>
<c>* </c>
<c>* ***   3.) EVALUATE   ***</c>
<c>* </c>
<c>* Set generic evaluation parameters.</c>
<l>create_dict (GenParamEval)</l>
<l>set_dict_tuple (GenParamEval, 'class_names_to_evaluate', 'global')</l>
<l>set_dict_tuple (GenParamEval, 'measures', ['top1_error','precision','recall','f_score','absolute_confusion_matrix'])</l>
<c>* Evaluate the trained model.</c>
<l>evaluate_dl_model (DLDataset, DLModelHandle, 'split', 'test', GenParamEval, EvaluationResult, EvalParams)</l>
<c>* </c>
<l>create_dict (EvalDisplayMode)</l>
<l>set_dict_tuple (EvalDisplayMode, 'display_mode', ['measures','pie_charts_precision','pie_charts_recall','absolute_confusion_matrix'])</l>
<l>create_dict (WindowDict)</l>
<l>dev_display_classification_evaluation (EvaluationResult, EvalParams, EvalDisplayMode, WindowDict)</l>
<l>dev_disp_text ('Press F5 to continue', 'window', 'bottom', 'right', 'black', [], [])</l>
<l>stop ()</l>
<l>dev_close_window_dict (WindowDict)</l>
<c>* </c>
<c>* Optimize the model for inference,</c>
<c>* meaning, reduce its memory consumption.</c>
<l>set_dl_model_param (DLModelHandle, 'optimize_for_inference', 'true')</l>
<l>set_dl_model_param (DLModelHandle, 'batch_size', 1)</l>
<c>* Save the model in this optimized state.</c>
<l>write_dl_model (DLModelHandle, 'model_best.hdl')</l>
<c>* </c>
<c>* ***   4.) INFER   ***</c>
<c>* </c>
<c>* To demonstrate the inference steps, we apply the trained model to some randomly</c>
<c>* chosen example images.</c>
<l>list_image_files (RawImageFolder, 'default', 'recursive', ImageFiles)</l>
<l>create_dict (WindowDict)</l>
<l>for IndexInference := 0 to 9 by 1</l>
<l>    SampleIndex := round(rand(1) * (|DatasetSamples| - 1))</l>
<l>    read_image (Image, ImageFiles[SampleIndex])</l>
<l>    gen_dl_samples_from_images (Image, DLSample)</l>
<l>    preprocess_dl_samples (DLSample, DLPreprocessParam)</l>
<l>    apply_dl_model (DLModelHandle, DLSample, [], DLResult)</l>
<c>    * </c>
<l>    dev_display_dl_data (DLSample, DLResult, DLDataset, 'classification_result', [], WindowDict)</l>
<l>    stop ()</l>
<l>endfor</l>
<l>dev_close_window_dict (WindowDict)</l>
<c>* </c>
<c>* *** 5.) REMOVE FILES ***</c>
<c>* </c>
<l>clean_up_output (OutputDir, RemoveResults)</l>
</body>
<docu id="main">
<parameters/>
</docu>
</procedure>
<procedure name="clean_up_output">
<interface>
<ic>
<par name="OutputDir" base_type="ctrl" dimension="0"/>
<par name="RemoveResults" base_type="ctrl" dimension="0"/>
</ic>
</interface>
<body>
<c>* This local example procedure cleans up the output of the example.</c>
<c></c>
<l>if (not RemoveResults)</l>
<l>    return ()</l>
<l>endif</l>
<c>* Display a warning.</c>
<l>dev_open_window (0, 0, 600, 300, 'black', WindowHandle)</l>
<l>set_display_font (WindowHandle, 16, 'mono', 'true', 'false')</l>
<l>WarningCleanup := ['Congratulations, you have finished the example.','','Unless you would like to use the output data / model,','press F5 to clean up.']</l>
<l>dev_disp_text (WarningCleanup, 'window', 'center', 'center', ['black','black','coral','coral','coral'], [], [])</l>
<c></c>
<l>stop ()</l>
<l>dev_close_window ()</l>
<c></c>
<c>* Delete all outputs of the example.</c>
<l>remove_dir_recursively (OutputDir)</l>
<l>delete_file ('model_best.hdl')</l>
<l>delete_file ('model_best_info.hdict')</l>
<l>return ()</l>
</body>
<docu id="clean_up_output">
<parameters>
<parameter id="OutputDir"/>
<parameter id="RemoveResults"/>
</parameters>
</docu>
</procedure>
</hdevelop>
